### 20/03/06

开始撸代码了！先了解一下movieLens数据集的内容~

* tags.csv
  
    userId<br>
    movieId<br>
    tag：由用户决定<br>
    timestamp：自1970年1月1日零点后到用户提交评价的时间的秒数<br>

* ratings.csv
  userId<br>
  movieId<br>
  rating：0.5~5.0<br>
  timestamp<br>

* movies.csv
  movieId:193609<br>
  title<br>
  genres：给定的分类，一部影片可以跨越多个分类<br>

* links.csv
  movieId<br>
  imdbId：应该是在imdb这个网站中的id<br>
  tmdbId：themoviedb上的id<br>
  上面这俩都可以在网站中找到<br>

con：好像也没干啥，弄清楚了dataset里面都有啥。然后有了前车之鉴，这一次搭的虚环境。<br>

### 2020/03/07

* 读文件的问题解决了
* ahp算法在写了

### 2020/03/08

* 其实读文件内一步应该改进一下的，不读空行的话严谨一些(算了没大碍)
* 评论，点击，评分的统计都整完了，直接放在了listMovie的全局变量里，现在想来是不是用numpy数组会好一些？

### 2020/03/09

* ahp部分整好了，但是你撸代码也太不严谨啦！！！超级多小bug
* ahp三个权重**基本是一样**的……考虑后期如果想加大难度可以再考虑其他因素，比如活跃人口比重
* 顺带一提哦，运气好，刚好ahp部分是满足一致性的！

### 2020/0310

* 获取最热门视频集合部分已经撸完了！得到的是index
* 然后……就没啥了……

### 2020/0311

* 其实在推荐部分，用户的那一块儿，可以针对用户分级，等级越高，用户打分的权重越高，因为活跃用户肯定比不活跃用户要重要，**等后面工作量不够了再加？**
* 一开始一直纠结于，我把这个dataset作为一个edge node服务的用户集，然后抽取前50个hot movies，再构建用户评分矩阵是不是有点多此一举，毕竟每个电影的评分不是已经有了么，但是，这里情况是这样，不代表其他的是哇，在现实环境下，一个edge node的用户基本没可能看过所有videos，所以，到时候用相同的办法，但是相似用户选择全体用户集，应该是没啥关系的--希望不要再出现问题惹

* 愁啊，我不想划分用户集合了，这样代码又要大改了。我觉得目前先用这个小范围的集合也没关系？只要最后能够得到推荐的东西就可以了吧？

### 2020/0312

* 数据清理真的好麻烦啊啊啊啊！！！终于把每个用户单独的观影记录拎出来了
* 我琢磨着你还是懂得太少了，python用到现在才只会list和array……多学学啊！！

### 2020/0313

* 终于撸出来用户矩阵咯，但是还有个小问题就是……emmm，咱也不知道算出来的到底对不对……
* 明天就接着撸出推荐电影集把！

### 2020/0314

* cheer up!!!推荐部分撸完了！！！但是咱也不知道结果到底对不对……
* **下周给老师汇报的时候就！！！要问一下这样到底行不行**
* 接下来就要定一下怎么替换了，我觉得也可以看成流行度预测的问题，也可以用猴群算法~~~

### 2020/0316

* 遗留了一些问题要fix，等到要写论文了再说？
* 还有个很重要的！！！**把数据分为验证和训练两部分的问题！**

### 20200321

* 关于数据集更多信息 It contains 100836 ratings and 3683 tag applications across 9742 movies. These data were created by 610 users **between March 29, 1996 and September 24, 2018.**

* 那么问题来了？为什么测试的结果那么好？
  * 可能是本身训练15年，测试7年，7年观影量很大了，所以可能基本推荐的都看过了
  * whatever，再想想把

