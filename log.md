### 20/03/06

开始撸代码了！先了解一下movieLens数据集的内容~

* tags.csv
  
    userId<br>
    movieId<br>
    tag：由用户决定<br>
    timestamp：自1970年1月1日零点后到用户提交评价的时间的秒数<br>

* ratings.csv
  userId<br>
  movieId<br>
  rating：0.5~5.0<br>
  timestamp<br>

* movies.csv
  movieId:193609<br>
  title<br>
  genres：给定的分类，一部影片可以跨越多个分类<br>

* links.csv
  movieId<br>
  imdbId：应该是在imdb这个网站中的id<br>
  tmdbId：themoviedb上的id<br>
  上面这俩都可以在网站中找到<br>

con：好像也没干啥，弄清楚了dataset里面都有啥。然后有了前车之鉴，这一次搭的虚环境。<br>

### 2020/03/07

* 读文件的问题解决了
* ahp算法在写了

### 2020/03/08

* 其实读文件内一步应该改进一下的，不读空行的话严谨一些(算了没大碍)
* 评论，点击，评分的统计都整完了，直接放在了listMovie的全局变量里，现在想来是不是用numpy数组会好一些？

### 2020/03/09

* ahp部分整好了，但是你撸代码也太不严谨啦！！！超级多小bug
* ahp三个权重**基本是一样**的……考虑后期如果想加大难度可以再考虑其他因素，比如活跃人口比重
* 顺带一提哦，运气好，刚好ahp部分是满足一致性的！

### 2020/0310

* 获取最热门视频集合部分已经撸完了！得到的是index
* 然后……就没啥了……

### 2020/0311

* 其实在推荐部分，用户的那一块儿，可以针对用户分级，等级越高，用户打分的权重越高，因为活跃用户肯定比不活跃用户要重要，**等后面工作量不够了再加？**
* 一开始一直纠结于，我把这个dataset作为一个edge node服务的用户集，然后抽取前50个hot movies，再构建用户评分矩阵是不是有点多此一举，毕竟每个电影的评分不是已经有了么，但是，这里情况是这样，不代表其他的是哇，在现实环境下，一个edge node的用户基本没可能看过所有videos，所以，到时候用相同的办法，但是相似用户选择全体用户集，应该是没啥关系的--希望不要再出现问题惹

* 愁啊，我不想划分用户集合了，这样代码又要大改了。我觉得目前先用这个小范围的集合也没关系？只要最后能够得到推荐的东西就可以了吧？


